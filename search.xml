<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[paper-of-quantization]]></title>
    <url>%2F2019%2F01%2F11%2Fpaper-of-quantization%2F</url>
    <content type="text"><![CDATA[Related papers Deep learning with limited numerical precision. 2015 IBM DoReFa-Net: Training low bit-width convolutional neural networks with low bit-width gradients. 2016 XNOR-Net: ImageNet Classification using binary convolutional neural networks. 2016 washington BC: Binary connect. BNN: Binarized Neural Networks. NIPS2016 Fixed point quantization of deep convolutional networks. 2016 Hardware-oriented approximation of convolutional neural networks. ICLR2016 TWNs: Ternary weight networks. NIPS2016 ucas Quantized convolutional neural networks for mobile devices. CVPR2016 nlpr Flexpoint: an adaptive numerical format for efficient training of deep neural networks. 2017 intel INQ: Incremental network quantization, towards lossless CNNs with low-precision weights. ICLR2017 intel labs china TTQ: Trained ternary quantization. ICLR2017 stanford WRPN: wide reduced-precision networks. 2017 detailed A Survey of Model Compression and Acceleration for Deep Neural Networks. 201712 VNQ: Variational network quantization. ICLR2018 WAGE: Training and Inference with Integers in Deep Neural Networks. ICLR2018 oral tsinghua Clip-Q: Deep network compression learning by In-Parallel Pruning Quantization. CVPR2018 SFU LQ-NETs: learned quantization for highly accurate and compact deep neural networks. ECCV2018 Microsoft Bi-Real Net: Enhancing the performance of 1-bit CNNs with improved Representational capability and advanced training algorithm. ECCV2018 HKU Synergy: Algorithm-hardware co-design for convnet accelerators on embedded FPGAs. 2018 UC Berkeley Alternating multi-bit quantization for recurrent neural networks. ICLR2018 alibaba Efficient Non-uniform quantizer for quantized neural network targeting Re-configurable hardware. 2018 ELQ: Explicit loss-error-aware quantization for low-bit deep neural networks. CVPR2018 intel tsinghua From Hashing to CNNs: training Binary weights vis hashing. AAAI2018 nlpr HAQ: Hardware-Aware automated quantization. NIPS workshop2018 mit Heterogeneous Bitwidth Binarization in Convolutional Neural Networks. NIPS2018 microsoft HALP: High-Accuracy Low-Precision Training. 2018 stanford Mixed Precision Training. ICLR2018 baidu PACT: parameterized clipping activation for quantized neural networks. 2018 IBM Model Compression via distillation and quantization. ICLR2018 google Quantization and training of neural networks for efficient integer-arithmetic-only inference. CVPR2018 Google Quantized back-propagation: training binarized neural networks with quantized gradients. ICLR2018 QUENN: Quantization engine for low-power neural networks. CF18 ACM Scalable methods for 8-bits training of neural networks. NIPS2018 intel SYQ: learning symmetric quantization for efficient deep neural networks. CVPR2018 xilinx TSQ: two-step quantization for low-bit neural networks. CVPR2018 V-Quant: Value-aware quantization for training and inference of neural networks. ECCV2018 facebook UNIQ: Uniform noise injection for non-uniform quantization of neural networks. 2018 Training a binary weight object detector by knowledge transfer for autonomous driving. 2018 Training competitive binary neural networks from scratch. 2018 A white-paper: Quantizing deep convolutional networks for efficient inference. 2018 google ACIQ: analytical clipping for integer quantization of neural networks. ICLR2019 Intel Per-Tensor Fixed-point quantization of the back-propagation algorithm. ICLR2019]]></content>
      <tags>
        <tag>quantization</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mxnet-build-from-source]]></title>
    <url>%2F2019%2F01%2F08%2Fmxnet-build-from-source%2F</url>
    <content type="text"><![CDATA[Build MXNet from SourceClone the MXNet Project12git clone --recursive https://github.com/apache/incubator-mxnet mxnetcd mxnet Download mklcudnn12cd 3rdparty/mkldnn/externalwget https://github.com/intel/mkl-dnn/releases/download/v0.17.2/mklml_lnx_2019.0.1.20180928.tgz Build12cd docs/install ./install_mxnet_ubuntu_python.sh install python12cd pythonpip install -e . Add operator in backendWhy not add custom operator using PythonOp interface.123456789class NDArrayOp(PythonOp): """Base class for numpy operators. numpy operators allow parts of computation in symbolic graph to be writen in numpy. This feature is intended for quickly hacking out a solution for non performance critical parts. Please consider write a c++ implementation if it becomes a bottleneck. Note that if your operator contains internal states (like arrays), it cannot be used for multi-gpu training. """ Referencesinstall-mxnet-for-pythonadd op in backend]]></content>
      <tags>
        <tag>MXNet</tag>
        <tag>GLUON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install-tensorRT]]></title>
    <url>%2F2018%2F10%2F26%2Finstall-tensorRT%2F</url>
    <content type="text"><![CDATA[Install Driver and CUDAinstall cuda Install TensorRTDownload TensorRT 5.0tensorrt download Then, I got the following package:nv-tensorrt-repo-ubuntu1604-cuda9.0-trt5.0.0.10-rc-20180906_1-1_amd64.deb Install TensorRT 5.01234567sudo dpkg -i nv-tensorrt-repo-ubuntu1604-cuda9.0-trt5.0.0.10-rc-20180906_1-1_amd64.debsudo apt-key add /var/nv-tensorrt-repo-cuda9.0-trt5.0.0.10-rc-20180906/7fa2af80.pub sudo apt-get update# Unluckily, I encountered the following problem.## double free or corruption (fasttop): 0x0000000001368e00 ***# I solved it by run: sudo apt-get purge libappstream3 sudo apt-get install tensorrt Demo1234cd /usr/src/tensorrt/samplessudo make -j32cd ../bin./samples_mnist Install PyCUDA12345678pip install pycuda# error# In file included from src/cpp/cuda.cpp:1:0:# src/cpp/cuda.hpp:14:18: fatal error: cuda.h: No such file or directory# compilation terminated.# error: command 'gcc' failed with exit status 1export PATH=/usr/local/cuda/bin:$PATHpip install pycuda uff custom plugin123456cd /usr/src/tensorrt/samples/python/uff_custom_pluginmkdir build &amp;&amp; pushd buildcmake ..make -j8python2 lenet5.pypython2 mnist_uff_custom_plugin.py]]></content>
      <tags>
        <tag>cuda</tag>
        <tag>nvidia-driver</tag>
        <tag>ubuntu</tag>
        <tag>tensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install-cuda]]></title>
    <url>%2F2018%2F10%2F18%2Finstall-cuda%2F</url>
    <content type="text"><![CDATA[Update /etc/apt/source.listBase software12345678sudo apt-get install vimsudo apt-get install screensudo apt-get install gitsudo apt-get install zshsh -c "$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)"sudo apt-get install htopsudo apt-get install graphvizsudo apt-get install unrar CUDA9.01234567891011121314cd /home/ict/Downloads/cuda9# nvidia-driversudo dpkg -i nvidia-driver-local-repo-ubuntu1604-387.34_1.0-1_amd64.debsudo apt-get updatesudo apt-get install cuda-driverssudo reboot# cuda9.0cd /home/ict/Downloads/cuda9sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-debsudo apt-get updatesudo apt-get install cuda# cudnnsudo dpkg -i libcudnn7-dev_7.1.3.16-1+cuda9.0_amd64.debsudo dpkg -i libcudnn7_7.1.3.16-1+cuda9.0_amd64.deb Remove CUDA1sudo apt-get --purge remove "nvidia-*" Using the specified GPU1CUDA_VISIBLE_DEVICES="0,1"]]></content>
      <tags>
        <tag>cuda</tag>
        <tag>nvidia-driver</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-command]]></title>
    <url>%2F2018%2F09%2F29%2Fgit-command%2F</url>
    <content type="text"><![CDATA[Git commandupdate a forked repo from remote repo.123456789git remote add upstream git@github.com:&lt;custom&gt;.gitgit remote -vgit fetch upstreamgit merge upstream/mastergit push git 合并多个commits合并多个 Commit git拉取远程分支到本地查看远程分支1git branch -r 拉取远程分支到本地分支1git checkout -b 本地分支名x origin/远程分支名x 取消本地修改1234git checkout . #本地所有修改的。没有的提交的，都返回到原来的状态git stash #把所有没有提交的修改暂存到stash里面。可用git stash pop回复。git reset --hard HASH #返回到某个节点，不保留修改。git reset --soft HASH #返回到某个节点。保留修改]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[anaconda-config]]></title>
    <url>%2F2018%2F09%2F28%2Fanaconda-config%2F</url>
    <content type="text"><![CDATA[Install anaconda on MacOS清华镜像站 1bash Anaconda3 Install cv21conda install -c menpo opencv]]></content>
      <tags>
        <tag>anaconda python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycaffe config]]></title>
    <url>%2F2018%2F08%2F27%2Fpycaffe-config%2F</url>
    <content type="text"><![CDATA[ProblemThere is always some trouble when we want use pycaffe and opencv at the same time :(12import caffeimport cv2 Solution We just do not use Anaconda!!!!! 123cd caffe/pythonfor req in $(cat requirements.txt); do pip install $req; donepip install opencv-python 12345678910111213141516import os.path as ospimport sysdef add_path(path): if path not in sys.path: sys.path.insert(0, path)caffe_path = '/home/zhaoxiandong/caffe'# Add caffe to PYTHONPATHcaffe_path = osp.join(caffe_path, 'python')add_path(caffe_path)import caffeimport cv2# successful !::::)))) Referenceshttps://github.com/NVIDIA/DIGITS/issues/156]]></content>
      <tags>
        <tag>pycaffe</tag>
        <tag>caffe</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch Begin]]></title>
    <url>%2F2018%2F08%2F10%2FPyTorch-Begin%2F</url>
    <content type="text"><![CDATA[Recommand approach for saving modelStack overflow First 12345# savetorch.save(model.state_dict(), PATH)# loadmodel = Model(args)model.load_state_dict(torch.load(PATH)) Second 1234# savetorch.save(mode, PATH)# loadmodel = torch.load(PATH) Pytorch DataParallelcsdn]]></content>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh tunnel 端口转发]]></title>
    <url>%2F2018%2F08%2F09%2Fssh-tunnel-%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Problem description A PC B 有公网IP的服务器或者工作站 C 和B在同一个局域网的机器 D 任意一台能联网的机器 我们想通过PC来连接B, C, D, 从而方便的来远程同步代码，和开启jupyter-notebook服务等。 ssh command主要用到了下边这条命令： 1ssh -N -f -L &lt;port2&gt;:&lt;ip1&gt;:&lt;port1&gt; &lt;username&gt;@&lt;ip&gt; N 在后台运行 f Fork into background after authentication. 后台认证用户密码，通常和-N连用，不用登录到远程主机。 L 本地起端口映射到其他机器 ExampleAccess server C on PC ARun on PC A:1ssh -N -f -L &lt;A.custom.port&gt;:&lt;C.local.ip&gt;:&lt;C.custom.port&gt; &lt;username&gt;@&lt;B.public.ip&gt; Access server D on PC ARun on server D:1ssh -CfnNt -R &lt;B.custom.port&gt;:localhost:&lt;D.custom.port&gt; &lt;username&gt;@&lt;B.public.ip&gt; Run on PC A:1ssh -N -f -L &lt;A.custom.port&gt;:localhost:&lt;B.custom.port&gt; &lt;username&gt;@&lt;B.public.ip&gt; A直接ssh登陆到CAdd the following code to ~/.ssh/config12345Host serverUser C.usernamePort 22HostName &lt;C.local.ip&gt;ProxyCommand ssh B.username@B.public.ip nc %h %p 2&gt; /dev/null Then, we can connect to server C directly.1ssh server Reference梦溪博客]]></content>
      <tags>
        <tag>ssh tunnel</tag>
        <tag>sublime</tag>
        <tag>sftp</tag>
        <tag>jupyter-notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python argparse]]></title>
    <url>%2F2018%2F08%2F08%2Fpython-argparse%2F</url>
    <content type="text"><![CDATA[Usage1234import argparseparser= argparse.ArgumentParser()parser = argparse.ArgumentParser(description='')parser.add_argument('data', metavar='DIR', help='path to dataset') Parameter prog - The name of the program (default: sys.argv[0]) usage - The string describing the program usage (default: generated from arguments added to parser) description - Text to display before the argument help (default: none) epilog - Text to display after the argument help (default: none) parents - A list of ArgumentParser objects whose arguments should also be included formatter_class - A class for customizing the help output prefix_chars - The set of characters that prefix optional arguments (default: ‘-‘) fromfile_prefix_chars - The set of characters that prefix files from which additional arguments should be read (default: None) argument_default - The global default value for arguments (default: None) conflict_handler - The strategy for resolving conflicting optionals (usually unnecessary) add_help - Add a -h/–help option to the parser (default: True) allow_abbrev - Allows long options to be abbreviated if the abbreviation is unambiguous. (default: True) The add_augment() method name or flags - Either a name or a list of option strings, e.g. foo or -f, –foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. 有助于提醒用户，该命令行参数所期待的参数，如 metavar=”mode” dest - The name of the attribute to be added to the object returned by parse_args(). ReferencePython 命令行解析python.org]]></content>
      <tags>
        <tag>python</tag>
        <tag>argparse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2018%2F08%2F07%2Ftest%2F</url>
    <content type="text"><![CDATA[test $$\begin{eqnarray}\nabla\cdot\vec{E} &amp;=&amp; \frac{\rho}{\epsilon_0} \\\nabla\cdot\vec{B} &amp;=&amp; 0 \\\nabla\times\vec{E} &amp;=&amp; -\frac{\partial B}{\partial t} \\\nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right)\end{eqnarray}$$]]></content>
  </entry>
</search>
