<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mxnet-build-from-source]]></title>
    <url>%2F2019%2F01%2F08%2Fmxnet-build-from-source%2F</url>
    <content type="text"><![CDATA[Build MXNet from SourceClone the MXNet Project12git clone --recursive https://github.com/apache/incubator-mxnet mxnetcd mxnet Download mklcudnn12cd 3rdparty/mkldnn/externalwget https://github.com/intel/mkl-dnn/releases/download/v0.17.2/mklml_lnx_2019.0.1.20180928.tgz Build12cd docs/install ./install_mxnet_ubuntu_python.sh install python12cd pythonpip install -e . Add operator in backendWhy not add custom operator using PythonOp interface.123456789class NDArrayOp(PythonOp): """Base class for numpy operators. numpy operators allow parts of computation in symbolic graph to be writen in numpy. This feature is intended for quickly hacking out a solution for non performance critical parts. Please consider write a c++ implementation if it becomes a bottleneck. Note that if your operator contains internal states (like arrays), it cannot be used for multi-gpu training. """ Referencesnstall-mxnet-for-pythonadd op in backend]]></content>
      <tags>
        <tag>MXNet</tag>
        <tag>GLUON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MXNet-begin]]></title>
    <url>%2F2018%2F12%2F08%2FMXNet-begin%2F</url>
    <content type="text"><![CDATA[# Add custom layerF12 F.__all__[&apos;CachedOp&apos;, &apos;Activation&apos;, &apos;BatchNorm&apos;, &apos;BatchNorm_v1&apos;, &apos;BilinearSampler&apos;, &apos;BlockGrad&apos;, &apos;Cast&apos;, &apos;Concat&apos;, &apos;Convolution&apos;, &apos;Convolution_v1&apos;, &apos;Correlation&apos;, &apos;Crop&apos;, &apos;CuDNNBatchNorm&apos;, &apos;Custom&apos;, &apos;Deconvolution&apos;, &apos;Dropout&apos;, &apos;ElementWiseSum&apos;, &apos;Embedding&apos;, &apos;Flatten&apos;, &apos;FullyConnected&apos;, &apos;GridGenerator&apos;, &apos;IdentityAttachKLSparseReg&apos;, &apos;InstanceNorm&apos;, &apos;L2Normalization&apos;, &apos;LRN&apos;, &apos;LayerNorm&apos;, &apos;LeakyReLU&apos;, &apos;LinearRegressionOutput&apos;, &apos;LogisticRegressionOutput&apos;, &apos;MAERegressionOutput&apos;, &apos;MakeLoss&apos;, &apos;Pad&apos;, &apos;Pooling&apos;, &apos;Pooling_v1&apos;, &apos;RNN&apos;, &apos;ROIPooling&apos;, &apos;Reshape&apos;, &apos;SVMOutput&apos;, &apos;SequenceLast&apos;, &apos;SequenceMask&apos;, &apos;SequenceReverse&apos;, &apos;SliceChannel&apos;, &apos;Softmax&apos;, &apos;SoftmaxActivation&apos;, &apos;SoftmaxOutput&apos;, &apos;SpatialTransformer&apos;, &apos;SwapAxis&apos;, &apos;UpSampling&apos;, &apos;abs&apos;, &apos;adam_update&apos;, &apos;add_n&apos;, &apos;arccos&apos;, &apos;arccosh&apos;, &apos;arcsin&apos;, &apos;arcsinh&apos;, &apos;arctan&apos;, &apos;arctanh&apos;, &apos;argmax&apos;, &apos;argmax_channel&apos;, &apos;argmin&apos;, &apos;argsort&apos;, &apos;batch_dot&apos;, &apos;batch_take&apos;, &apos;broadcast_add&apos;, &apos;broadcast_axes&apos;, &apos;broadcast_axis&apos;, &apos;broadcast_div&apos;, &apos;broadcast_equal&apos;, &apos;broadcast_greater&apos;, &apos;broadcast_greater_equal&apos;, &apos;broadcast_hypot&apos;, &apos;broadcast_lesser&apos;, &apos;broadcast_lesser_equal&apos;, &apos;broadcast_like&apos;, &apos;broadcast_logical_and&apos;, &apos;broadcast_logical_or&apos;, &apos;broadcast_logical_xor&apos;, &apos;broadcast_maximum&apos;, &apos;broadcast_minimum&apos;, &apos;broadcast_minus&apos;, &apos;broadcast_mod&apos;, &apos;broadcast_mul&apos;, &apos;broadcast_not_equal&apos;, &apos;broadcast_plus&apos;, &apos;broadcast_power&apos;, &apos;broadcast_sub&apos;, &apos;broadcast_to&apos;, &apos;cast&apos;, &apos;cast_storage&apos;, &apos;cbrt&apos;, &apos;ceil&apos;, &apos;choose_element_0index&apos;, &apos;clip&apos;, &apos;concat&apos;, &apos;cos&apos;, &apos;cosh&apos;, &apos;crop&apos;, &apos;degrees&apos;, &apos;depth_to_space&apos;, &apos;diag&apos;, &apos;dot&apos;, &apos;elemwise_add&apos;, &apos;elemwise_div&apos;, &apos;elemwise_mul&apos;, &apos;elemwise_sub&apos;, &apos;exp&apos;, &apos;expand_dims&apos;, &apos;expm1&apos;, &apos;fill_element_0index&apos;, &apos;fix&apos;, &apos;flatten&apos;, &apos;flip&apos;, &apos;floor&apos;, &apos;ftml_update&apos;, &apos;ftrl_update&apos;, &apos;gamma&apos;, &apos;gammaln&apos;, &apos;gather_nd&apos;, &apos;hard_sigmoid&apos;, &apos;identity&apos;, &apos;khatri_rao&apos;, &apos;linalg_gelqf&apos;, &apos;linalg_gemm&apos;, &apos;linalg_gemm2&apos;, &apos;linalg_potrf&apos;, &apos;linalg_potri&apos;, &apos;linalg_sumlogdiag&apos;, &apos;linalg_syrk&apos;, &apos;linalg_trmm&apos;, &apos;linalg_trsm&apos;, &apos;log&apos;, &apos;log10&apos;, &apos;log1p&apos;, &apos;log2&apos;, &apos;log_softmax&apos;, &apos;logical_not&apos;, &apos;make_loss&apos;, &apos;max&apos;, &apos;max_axis&apos;, &apos;mean&apos;, &apos;min&apos;, &apos;min_axis&apos;, &apos;mp_sgd_mom_update&apos;, &apos;mp_sgd_update&apos;, &apos;nanprod&apos;, &apos;nansum&apos;, &apos;negative&apos;, &apos;norm&apos;, &apos;normal&apos;, &apos;one_hot&apos;, &apos;ones_like&apos;, &apos;pad&apos;, &apos;pick&apos;, &apos;prod&apos;, &apos;radians&apos;, &apos;random_exponential&apos;, &apos;random_gamma&apos;, &apos;random_generalized_negative_binomial&apos;, &apos;random_negative_binomial&apos;, &apos;random_normal&apos;, &apos;random_poisson&apos;, &apos;random_uniform&apos;, &apos;ravel_multi_index&apos;, &apos;rcbrt&apos;, &apos;reciprocal&apos;, &apos;relu&apos;, &apos;repeat&apos;, &apos;reshape&apos;, &apos;reshape_like&apos;, &apos;reverse&apos;, &apos;rint&apos;, &apos;rmsprop_update&apos;, &apos;rmspropalex_update&apos;, &apos;round&apos;, &apos;rsqrt&apos;, &apos;sample_exponential&apos;, &apos;sample_gamma&apos;, &apos;sample_generalized_negative_binomial&apos;, &apos;sample_multinomial&apos;, &apos;sample_negative_binomial&apos;, &apos;sample_normal&apos;, &apos;sample_poisson&apos;, &apos;sample_uniform&apos;, &apos;scatter_nd&apos;, &apos;sgd_mom_update&apos;, &apos;sgd_update&apos;, &apos;shape_array&apos;, &apos;shuffle&apos;, &apos;sigmoid&apos;, &apos;sign&apos;, &apos;signsgd_update&apos;, &apos;signum_update&apos;, &apos;sin&apos;, &apos;sinh&apos;, &apos;size_array&apos;, &apos;slice&apos;, &apos;slice_axis&apos;, &apos;slice_like&apos;, &apos;smooth_l1&apos;, &apos;softmax&apos;, &apos;softmax_cross_entropy&apos;, &apos;softsign&apos;, &apos;sort&apos;, &apos;space_to_depth&apos;, &apos;split&apos;, &apos;sqrt&apos;, &apos;square&apos;, &apos;squeeze&apos;, &apos;stack&apos;, &apos;stop_gradient&apos;, &apos;sum&apos;, &apos;sum_axis&apos;, &apos;swapaxes&apos;, &apos;take&apos;, &apos;tan&apos;, &apos;tanh&apos;, &apos;tile&apos;, &apos;topk&apos;, &apos;transpose&apos;, &apos;trunc&apos;, &apos;uniform&apos;, &apos;unravel_index&apos;, &apos;where&apos;, &apos;zeros_like&apos;, &apos;NDArray&apos;, &apos;concatenate&apos;, &apos;_DTYPE_NP_TO_MX&apos;, &apos;_DTYPE_MX_TO_NP&apos;, &apos;_GRAD_REQ_MAP&apos;, &apos;ones&apos;, &apos;add&apos;, &apos;arange&apos;, &apos;eye&apos;, &apos;divide&apos;, &apos;equal&apos;, &apos;full&apos;, &apos;greater&apos;, &apos;greater_equal&apos;, &apos;imdecode&apos;, &apos;lesser&apos;, &apos;lesser_equal&apos;, &apos;logical_and&apos;, &apos;logical_or&apos;, &apos;logical_xor&apos;, &apos;maximum&apos;, &apos;minimum&apos;, &apos;moveaxis&apos;, &apos;modulo&apos;, &apos;multiply&apos;, &apos;not_equal&apos;, &apos;onehot_encode&apos;, &apos;power&apos;, &apos;subtract&apos;, &apos;true_divide&apos;, &apos;waitall&apos;, &apos;_new_empty_handle&apos;, &apos;histogram&apos;, &apos;zeros&apos;, &apos;empty&apos;, &apos;array&apos;, &apos;load&apos;, &apos;load_frombuffer&apos;, &apos;save&apos;, &apos;contrib&apos;, &apos;linalg&apos;, &apos;random&apos;, &apos;sparse&apos;, &apos;image&apos;]]]></content>
      <tags>
        <tag>MXNet</tag>
        <tag>GLUON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install-tensorRT]]></title>
    <url>%2F2018%2F10%2F26%2Finstall-tensorRT%2F</url>
    <content type="text"><![CDATA[Install Driver and CUDAinstall cuda Install TensorRTDownload TensorRT 5.0tensorrt download Then, I got the following package:nv-tensorrt-repo-ubuntu1604-cuda9.0-trt5.0.0.10-rc-20180906_1-1_amd64.deb Install TensorRT 5.01234567sudo dpkg -i nv-tensorrt-repo-ubuntu1604-cuda9.0-trt5.0.0.10-rc-20180906_1-1_amd64.debsudo apt-key add /var/nv-tensorrt-repo-cuda9.0-trt5.0.0.10-rc-20180906/7fa2af80.pub sudo apt-get update# Unluckily, I encountered the following problem.## double free or corruption (fasttop): 0x0000000001368e00 ***# I solved it by run: sudo apt-get purge libappstream3 sudo apt-get install tensorrt Demo1234cd /usr/src/tensorrt/samplessudo make -j32cd ../bin./samples_mnist Install PyCUDA12345678pip install pycuda# error# In file included from src/cpp/cuda.cpp:1:0:# src/cpp/cuda.hpp:14:18: fatal error: cuda.h: No such file or directory# compilation terminated.# error: command 'gcc' failed with exit status 1export PATH=/usr/local/cuda/bin:$PATHpip install pycuda uff custom plugin123456cd /usr/src/tensorrt/samples/python/uff_custom_pluginmkdir build &amp;&amp; pushd buildcmake ..make -j8python2 lenet5.pypython2 mnist_uff_custom_plugin.py]]></content>
      <tags>
        <tag>cuda</tag>
        <tag>nvidia-driver</tag>
        <tag>ubuntu</tag>
        <tag>tensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install-cuda]]></title>
    <url>%2F2018%2F10%2F18%2Finstall-cuda%2F</url>
    <content type="text"><![CDATA[Update /etc/apt/source.listBase software12345678sudo apt-get install vimsudo apt-get install screensudo apt-get install gitsudo apt-get install zshsh -c "$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)"sudo apt-get install htopsudo apt-get install graphvizsudo apt-get install unrar CUDA9.01234567891011121314cd /home/ict/Downloads/cuda9# nvidia-driversudo dpkg -i nvidia-driver-local-repo-ubuntu1604-387.34_1.0-1_amd64.debsudo apt-get updatesudo apt-get install cuda-driverssudo reboot# cuda9.0cd /home/ict/Downloads/cuda9sudo dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-debsudo apt-get updatesudo apt-get install cuda# cudnnsudo dpkg -i libcudnn7-dev_7.1.3.16-1+cuda9.0_amd64.debsudo dpkg -i libcudnn7_7.1.3.16-1+cuda9.0_amd64.deb Remove CUDA1sudo apt-get --purge remove "nvidia-*" Using the specified GPU1CUDA_VISIBLE_DEVICES="0,1"]]></content>
      <tags>
        <tag>cuda</tag>
        <tag>nvidia-driver</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-command]]></title>
    <url>%2F2018%2F09%2F29%2Fgit-command%2F</url>
    <content type="text"><![CDATA[Git commandupdate a forked repo from remote repo.123456789git remote add upstream git@github.com:&lt;custom&gt;.gitgit remote -vgit fetch upstreamgit merge upstream/mastergit push git 合并多个commits合并多个 Commit git拉取远程分支到本地查看远程分支1git branch -r 拉取远程分支到本地分支1git checkout -b 本地分支名x origin/远程分支名x 取消本地修改1234git checkout . #本地所有修改的。没有的提交的，都返回到原来的状态git stash #把所有没有提交的修改暂存到stash里面。可用git stash pop回复。git reset --hard HASH #返回到某个节点，不保留修改。git reset --soft HASH #返回到某个节点。保留修改]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[anaconda-config]]></title>
    <url>%2F2018%2F09%2F28%2Fanaconda-config%2F</url>
    <content type="text"><![CDATA[Install anaconda on MacOS清华镜像站 1bash Anaconda3 Install cv21conda install -c menpo opencv]]></content>
      <tags>
        <tag>anaconda python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycaffe config]]></title>
    <url>%2F2018%2F08%2F27%2Fpycaffe-config%2F</url>
    <content type="text"><![CDATA[ProblemThere is always some trouble when we want use pycaffe and opencv at the same time :(12import caffeimport cv2 Solution We just do not use Anaconda!!!!! 123cd caffe/pythonfor req in $(cat requirements.txt); do pip install $req; donepip install opencv-python 12345678910111213141516import os.path as ospimport sysdef add_path(path): if path not in sys.path: sys.path.insert(0, path)caffe_path = '/home/zhaoxiandong/caffe'# Add caffe to PYTHONPATHcaffe_path = osp.join(caffe_path, 'python')add_path(caffe_path)import caffeimport cv2# successful !::::)))) Referenceshttps://github.com/NVIDIA/DIGITS/issues/156]]></content>
      <tags>
        <tag>pycaffe</tag>
        <tag>caffe</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch Begin]]></title>
    <url>%2F2018%2F08%2F10%2FPyTorch-Begin%2F</url>
    <content type="text"><![CDATA[Recommand approach for saving modelStack overflow First 12345# savetorch.save(model.state_dict(), PATH)# loadmodel = Model(args)model.load_state_dict(torch.load(PATH)) Second 1234# savetorch.save(mode, PATH)# loadmodel = torch.load(PATH) Pytorch DataParallelcsdn]]></content>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch Issues]]></title>
    <url>%2F2018%2F08%2F10%2FPyTorch-Issues%2F</url>
    <content type="text"></content>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh tunnel 端口转发]]></title>
    <url>%2F2018%2F08%2F09%2Fssh-tunnel-%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Problem description A PC B 有公网IP的服务器或者工作站 C 和B在同一个局域网的机器 D 任意一台能联网的机器 我们想通过PC来连接B, C, D, 从而方便的来远程同步代码，和开启jupyter-notebook服务等。 ssh command主要用到了下边这条命令： 1ssh -N -f -L &lt;port2&gt;:&lt;ip1&gt;:&lt;port1&gt; &lt;username&gt;@&lt;ip&gt; N 在后台运行 f Fork into background after authentication. 后台认证用户密码，通常和-N连用，不用登录到远程主机。 L 本地起端口映射到其他机器 ExampleAccess server C on PC ARun on PC A:1ssh -N -f -L &lt;A.custom.port&gt;:&lt;C.local.ip&gt;:&lt;C.custom.port&gt; &lt;username&gt;@&lt;B.public.ip&gt; Access server D on PC ARun on server D:1ssh -CfnNt -R &lt;B.custom.port&gt;:localhost:&lt;D.custom.port&gt; &lt;username&gt;@&lt;B.public.ip&gt; Run on PC A:1ssh -N -f -L &lt;A.custom.port&gt;:localhost:&lt;B.custom.port&gt; &lt;username&gt;@&lt;B.public.ip&gt; A直接ssh登陆到CAdd the following code to ~/.ssh/config12345Host serverUser C.usernamePort 22HostName &lt;C.local.ip&gt;ProxyCommand ssh B.username@B.public.ip nc %h %p 2&gt; /dev/null Then, we can connect to server C directly.1ssh server Reference梦溪博客]]></content>
      <tags>
        <tag>ssh tunnel</tag>
        <tag>sublime</tag>
        <tag>sftp</tag>
        <tag>jupyter-notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python argparse]]></title>
    <url>%2F2018%2F08%2F08%2Fpython-argparse%2F</url>
    <content type="text"><![CDATA[Usage1234import argparseparser= argparse.ArgumentParser()parser = argparse.ArgumentParser(description='')parser.add_argument('data', metavar='DIR', help='path to dataset') Parameter prog - The name of the program (default: sys.argv[0]) usage - The string describing the program usage (default: generated from arguments added to parser) description - Text to display before the argument help (default: none) epilog - Text to display after the argument help (default: none) parents - A list of ArgumentParser objects whose arguments should also be included formatter_class - A class for customizing the help output prefix_chars - The set of characters that prefix optional arguments (default: ‘-‘) fromfile_prefix_chars - The set of characters that prefix files from which additional arguments should be read (default: None) argument_default - The global default value for arguments (default: None) conflict_handler - The strategy for resolving conflicting optionals (usually unnecessary) add_help - Add a -h/–help option to the parser (default: True) allow_abbrev - Allows long options to be abbreviated if the abbreviation is unambiguous. (default: True) The add_augment() method name or flags - Either a name or a list of option strings, e.g. foo or -f, –foo. action - The basic type of action to be taken when this argument is encountered at the command line. nargs - The number of command-line arguments that should be consumed. const - A constant value required by some action and nargs selections. default - The value produced if the argument is absent from the command line. type - The type to which the command-line argument should be converted. choices - A container of the allowable values for the argument. required - Whether or not the command-line option may be omitted (optionals only). help - A brief description of what the argument does. metavar - A name for the argument in usage messages. 有助于提醒用户，该命令行参数所期待的参数，如 metavar=”mode” dest - The name of the attribute to be added to the object returned by parse_args(). ReferencePython 命令行解析python.org]]></content>
      <tags>
        <tag>python</tag>
        <tag>argparse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2018%2F08%2F07%2Ftest%2F</url>
    <content type="text"><![CDATA[test $$\begin{eqnarray}\nabla\cdot\vec{E} &amp;=&amp; \frac{\rho}{\epsilon_0} \\\nabla\cdot\vec{B} &amp;=&amp; 0 \\\nabla\times\vec{E} &amp;=&amp; -\frac{\partial B}{\partial t} \\\nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right)\end{eqnarray}$$]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
